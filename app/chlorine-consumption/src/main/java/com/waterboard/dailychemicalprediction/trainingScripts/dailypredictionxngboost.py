# -*- coding: utf-8 -*-
"""DailyPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pZ0qkSD32xUm0dyV_TmLmOsnvZt2Q4Ej
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error

# Load the dataset
df = pd.read_excel('water_treatment_data.xlsx')

# Define features and targets
features = ['Water Volume (Cubic Meters)', 'Initial Chlorine (ppm)', 'Initial pH', 'Initial Turbidity']
targets = ['Applied Chlorine (KG)', 'Applied Calcium Carbonate (KG)', 'Applied PAC (KG)']

X = df[features]
y = df[targets]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model for multi-output regression
model_xgb = MultiOutputRegressor(XGBRegressor(random_state=42))
model_xgb.fit(X_train, y_train)

# Predict on test set
y_pred = model_xgb.predict(X_test)

# Evaluate the model
rmse = mean_squared_error(y_test, y_pred, squared=False, multioutput='raw_values')
print("XGBoost RMSE for each target:", rmse)

# Example of user input data (one or more rows)
user_input = pd.DataFrame({
    'Water Volume (Cubic Meters)': [30550],
    'Initial Chlorine (ppm)': [0.12],
    'Initial pH': [3.06],
    'Initial Turbidity': [3.15]
})

# Predict using the trained XGBoost model
y_pred = model_xgb.predict(user_input)

# Display predictions
print("Predictions for user input:")
for target, pred in zip(targets, y_pred[0]):
    print(f"{target}: {pred:.4f} KG")

import joblib

# Save the trained model to a file
joblib.dump(model_xgb, 'xgboost_water_treatment_model.joblib')

import joblib

# Save the MultiOutputRegressor object with all its estimators
joblib.dump(model_xgb, "multi_output_model.pkl")

# Save each XGBRegressor model wrapped in the MultiOutputRegressor
for i, estimator in enumerate(model_xgb.estimators_):
    estimator.save_model(f"xgb_model_target_{i}.bin")



# Download the model
files.download('xgboost_water_treatment_model.joblib')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
df = pd.read_excel('water_treatment_data.xlsx')

# Define features and targets
features = ['Water Volume (Cubic Meters)', 'Initial Chlorine (ppm)', 'Initial pH', 'Initial Turbidity']
targets = ['Applied Chlorine (KG)', 'Applied Calcium Carbonate (KG)', 'Applied PAC (KG)']

X = df[features]
y = df[targets]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model for multi-output regression
rf_model = MultiOutputRegressor(RandomForestRegressor(random_state=42))
rf_model.fit(X_train, y_train)

# Train XGBoost model for multi-output regression
xgb_model = MultiOutputRegressor(XGBRegressor(random_state=42))
xgb_model.fit(X_train, y_train)

# Predict on test set using Random Forest
rf_pred = rf_model.predict(X_test)
# Predict on test set using XGBoost
xgb_pred = xgb_model.predict(X_test)

# Evaluate Random Forest Model
rf_rmse = mean_squared_error(y_test, rf_pred, squared=False, multioutput='raw_values')
rf_r2 = r2_score(y_test, rf_pred, multioutput='raw_values')

# Evaluate XGBoost Model
xgb_rmse = mean_squared_error(y_test, xgb_pred, squared=False, multioutput='raw_values')
xgb_r2 = r2_score(y_test, xgb_pred, multioutput='raw_values')

# Print Results for Random Forest
print("Random Forest Model Performance:")
print(f"RMSE for each target: {rf_rmse}")
print(f"R² for each target: {rf_r2}")
print("\n")

# Print Results for XGBoost
print("XGBoost Model Performance:")
print(f"RMSE for each target: {xgb_rmse}")
print(f"R² for each target: {xgb_r2}")

# Compare RMSE and R² to determine the best model
print("\nComparison of RMSE:")
print(f"Random Forest RMSE: {rf_rmse}")
print(f"XGBoost RMSE: {xgb_rmse}")

print("\nComparison of R²:")
print(f"Random Forest R²: {rf_r2}")
print(f"XGBoost R²: {xgb_r2}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error

# Load the dataset
df = pd.read_excel('water_treatment_data.xlsx')

# Define features and targets
features = ['Water Volume (Cubic Meters)', 'Initial Chlorine (ppm)', 'Initial pH', 'Initial Turbidity']
targets = ['Applied Chlorine (KG)', 'Applied Calcium Carbonate (KG)', 'Applied PAC (KG)']

X = df[features]
y = df[targets]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model for multi-output regression
model_xgb = MultiOutputRegressor(XGBRegressor(random_state=42))
model_xgb.fit(X_train, y_train)

# Save each XGBRegressor model wrapped in the MultiOutputRegressor
for i, estimator in enumerate(model_xgb.estimators_):
    estimator.save_model(f"xgb_model_target_{i}.bin")

# Predict on test set
y_pred = model_xgb.predict(X_test)

# Evaluate the model
rmse = mean_squared_error(y_test, y_pred, squared=False, multioutput='raw_values')
print("XGBoost RMSE for each target:", rmse)

def model_acc(model_xgb):
  acc = model_acc.score(X_test, Y_test)
  print(str(model)+ '-->' + str(acc))

from xgboost import XGBRegressor
from sklearn.multioutput import MultiOutputRegressor

# Load each individual XGBRegressor model
estimators = []
for i in range(len(targets)):
    xgb = XGBRegressor()
    xgb.load_model(f"xgb_model_target_{i}.bin")
    estimators.append(xgb)

# Reconstruct the MultiOutputRegressor with the loaded estimators
model_xgb = MultiOutputRegressor(estimators)

import xgboost as xgb
import pandas as pd

# Assuming you've already trained the model
# Example:
df = pd.read_excel('water_treatment_data.xlsx')

features = ['Water Volume (Cubic Meters)', 'Initial Chlorine (ppm)', 'Initial pH', 'Initial Turbidity']
targets = ['Applied Chlorine (KG)', 'Applied Calcium Carbonate (KG)', 'Applied PAC (KG)']

X = df[features]
y = df[targets]

# Train your XGBoost model
model_xgb = xgb.XGBRegressor(random_state=42)
model_xgb.fit(X, y)

# Save the trained model in .bin format
model_xgb.save_model('model.bin')

import xgboost as xgb
import numpy as np

# Load the saved model
model_xgb = xgb.XGBRegressor()
model_xgb.load_model('model.bin')

# Example input data (same features as during training)
test_data = np.array([[30550, 0.12, 3.06, 3.15]])  # Example values

# Perform prediction
predictions = model_xgb.predict(test_data)

# Output the predictions
print("Predictions for the given input:")
print(f"Applied Chlorine (KG): {predictions[0][0]:.4f}")
print(f"Applied Calcium Carbonate (KG): {predictions[0][1]:.4f}")
print(f"Applied PAC (KG): {predictions[0][2]:.4f}")